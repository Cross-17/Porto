{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# \n",
    "base_path = \"input/\"\n",
    "train=pd.read_csv(base_path + 'train.csv')\n",
    "test=pd.read_csv(base_path + 'test.csv')\n",
    "#more about kinetic features  developed  by Daia Alexandru    here  on the next  blog  please  read  last article :\n",
    "#https://alexandrudaia.quora.com/\n",
    "\n",
    "##############################################creatinng   kinetic features for  train #####################################################\n",
    "def  kinetic(row):\n",
    "    probs=np.unique(row,return_counts=True)[1]/len(row)\n",
    "    kinetic=np.sum(probs**2)\n",
    "    return kinetic\n",
    "    \n",
    "\n",
    "first_kin_names=[col for  col in train.columns  if '_ind_' in col]\n",
    "subset_ind=train[first_kin_names]\n",
    "kinetic_1=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_1.append(k)\n",
    "second_kin_names= [col for  col in train.columns  if '_car_' in col and col.endswith('cat')]\n",
    "subset_ind=train[second_kin_names]\n",
    "kinetic_2=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_2.append(k)\n",
    "third_kin_names= [col for  col in train.columns  if '_calc_' in col and  not col.endswith('bin')]\n",
    "subset_ind=train[second_kin_names]\n",
    "kinetic_3=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_3.append(k)\n",
    "fd_kin_names= [col for  col in train.columns  if '_calc_' in col and  col.endswith('bin')]\n",
    "subset_ind=train[fd_kin_names]\n",
    "kinetic_4=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_4.append(k)\n",
    "train['kinetic_1']=np.array(kinetic_1)\n",
    "train['kinetic_2']=np.array(kinetic_2)\n",
    "train['kinetic_3']=np.array(kinetic_3)\n",
    "train['kinetic_4']=np.array(kinetic_4)\n",
    "\n",
    "############################################reatinng   kinetic features for  test###############################################################\n",
    "\n",
    "first_kin_names=[col for  col in test.columns  if '_ind_' in col]\n",
    "subset_ind=test[first_kin_names]\n",
    "kinetic_1=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_1.append(k)\n",
    "second_kin_names= [col for  col in test.columns  if '_car_' in col and col.endswith('cat')]\n",
    "subset_ind=test[second_kin_names]\n",
    "kinetic_2=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_2.append(k)\n",
    "third_kin_names= [col for  col in test.columns  if '_calc_' in col and  not col.endswith('bin')]\n",
    "subset_ind=test[second_kin_names]\n",
    "kinetic_3=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_3.append(k)\n",
    "fd_kin_names= [col for  col in test.columns  if '_calc_' in col and  col.endswith('bin')]\n",
    "subset_ind=test[fd_kin_names]\n",
    "kinetic_4=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_4.append(k)\n",
    "test['kinetic_1']=np.array(kinetic_1)\n",
    "test['kinetic_2']=np.array(kinetic_2)\n",
    "test['kinetic_3']=np.array(kinetic_3)\n",
    "test['kinetic_4']=np.array(kinetic_4)\n",
    "\n",
    "##################################################################end  of kinetics ############################################################################\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "from multiprocessing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import *\n",
    "\n",
    "\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c:\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    #y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train, train['target'], test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = transform_df(x1)\n",
    "y1 = x1['target']\n",
    "x2 = transform_df(x2)\n",
    "y2 = x2['target']\n",
    "test = transform_df(test)\n",
    "\n",
    "col = [c for c in x1.columns if c not in ['id','target']]\n",
    "x1 = x1[col]\n",
    "x2 = x2[col]\n",
    "\n",
    "watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "model = xgb.train(params, xgb.DMatrix(x1, y1), 5000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "print(gini_xgb(model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), y2))\n",
    "test['target'] = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit)\n",
    "test[['id','target']].to_csv(base_path + 'test_uberKinetics.csv', index=False, float_format='%.5f')\n",
    "train = transform_df(train)\n",
    "train['target'] = model.predict(xgb.DMatrix(train[col]), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "train[['id','target']].to_csv(base_path + 'train_uberKinetics.csv', index=False, float_format='%.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
