{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crossbell\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Crossbell\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Crossbell\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# \n",
    "base_path = \"input/\"\n",
    "train=pd.read_csv(base_path + 'train.csv')\n",
    "test=pd.read_csv(base_path + 'test.csv')\n",
    "#more about kinetic features  developed  by Daia Alexandru    here  on the next  blog  please  read  last article :\n",
    "#https://alexandrudaia.quora.com/\n",
    "\n",
    "##############################################creatinng   kinetic features for  train #####################################################\n",
    "def  kinetic(row):\n",
    "    probs=np.unique(row,return_counts=True)[1]/len(row)\n",
    "    kinetic=np.sum(probs**2)\n",
    "    return kinetic\n",
    "    \n",
    "\n",
    "first_kin_names=[col for  col in train.columns  if '_ind_' in col]\n",
    "subset_ind=train[first_kin_names]\n",
    "kinetic_1=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_1.append(k)\n",
    "second_kin_names= [col for  col in train.columns  if '_car_' in col and col.endswith('cat')]\n",
    "subset_ind=train[second_kin_names]\n",
    "kinetic_2=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_2.append(k)\n",
    "third_kin_names= [col for  col in train.columns  if '_calc_' in col and  not col.endswith('bin')]\n",
    "subset_ind=train[second_kin_names]\n",
    "kinetic_3=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_3.append(k)\n",
    "fd_kin_names= [col for  col in train.columns  if '_calc_' in col and  col.endswith('bin')]\n",
    "subset_ind=train[fd_kin_names]\n",
    "kinetic_4=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_4.append(k)\n",
    "train['kinetic_1']=np.array(kinetic_1)\n",
    "train['kinetic_2']=np.array(kinetic_2)\n",
    "train['kinetic_3']=np.array(kinetic_3)\n",
    "train['kinetic_4']=np.array(kinetic_4)\n",
    "\n",
    "############################################reatinng   kinetic features for  test###############################################################\n",
    "\n",
    "first_kin_names=[col for  col in test.columns  if '_ind_' in col]\n",
    "subset_ind=test[first_kin_names]\n",
    "kinetic_1=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_1.append(k)\n",
    "second_kin_names= [col for  col in test.columns  if '_car_' in col and col.endswith('cat')]\n",
    "subset_ind=test[second_kin_names]\n",
    "kinetic_2=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_2.append(k)\n",
    "third_kin_names= [col for  col in test.columns  if '_calc_' in col and  not col.endswith('bin')]\n",
    "subset_ind=test[second_kin_names]\n",
    "kinetic_3=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_3.append(k)\n",
    "fd_kin_names= [col for  col in test.columns  if '_calc_' in col and  col.endswith('bin')]\n",
    "subset_ind=test[fd_kin_names]\n",
    "kinetic_4=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_4.append(k)\n",
    "test['kinetic_1']=np.array(kinetic_1)\n",
    "test['kinetic_2']=np.array(kinetic_2)\n",
    "test['kinetic_3']=np.array(kinetic_3)\n",
    "test['kinetic_4']=np.array(kinetic_4)\n",
    "\n",
    "##################################################################end  of kinetics ############################################################################\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "from multiprocessing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import *\n",
    "\n",
    "\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c:\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    #y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train, train['target'], test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until valid error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-auc:0.593750\tvalid-auc:0.591457\n",
      "[50]\ttrain-auc:0.621774\tvalid-auc:0.618708\n",
      "[100]\ttrain-auc:0.625400\tvalid-auc:0.621529\n",
      "[150]\ttrain-auc:0.632034\tvalid-auc:0.624779\n",
      "[200]\ttrain-auc:0.638926\tvalid-auc:0.628299\n",
      "[250]\ttrain-auc:0.644247\tvalid-auc:0.630823\n",
      "[300]\ttrain-auc:0.649415\tvalid-auc:0.633325\n",
      "[350]\ttrain-auc:0.653584\tvalid-auc:0.634883\n",
      "[400]\ttrain-auc:0.657280\tvalid-auc:0.636280\n",
      "[450]\ttrain-auc:0.660489\tvalid-auc:0.637117\n",
      "[500]\ttrain-auc:0.663309\tvalid-auc:0.637756\n",
      "[550]\ttrain-auc:0.665797\tvalid-auc:0.638059\n",
      "[600]\ttrain-auc:0.668535\tvalid-auc:0.638452\n",
      "[650]\ttrain-auc:0.671038\tvalid-auc:0.638729\n",
      "[700]\ttrain-auc:0.673369\tvalid-auc:0.638719\n",
      "[750]\ttrain-auc:0.675651\tvalid-auc:0.638896\n",
      "[800]\ttrain-auc:0.677828\tvalid-auc:0.639183\n",
      "[850]\ttrain-auc:0.679838\tvalid-auc:0.639194\n",
      "[900]\ttrain-auc:0.681754\tvalid-auc:0.639246\n",
      "[950]\ttrain-auc:0.683865\tvalid-auc:0.639375\n",
      "[1000]\ttrain-auc:0.685654\tvalid-auc:0.639368\n",
      "[1050]\ttrain-auc:0.687491\tvalid-auc:0.639475\n",
      "[1100]\ttrain-auc:0.689320\tvalid-auc:0.639431\n",
      "[1150]\ttrain-auc:0.691190\tvalid-auc:0.639571\n",
      "[1200]\ttrain-auc:0.692875\tvalid-auc:0.639465\n",
      "[1250]\ttrain-auc:0.694490\tvalid-auc:0.639339\n",
      "Stopping. Best iteration:\n",
      "[1154]\ttrain-auc:0.691292\tvalid-auc:0.639590\n",
      "\n",
      "('gini', 0.27918052961493683)\n"
     ]
    }
   ],
   "source": [
    "x1 = transform_df(x1)\n",
    "y1 = x1['target']\n",
    "x2 = transform_df(x2)\n",
    "y2 = x2['target']\n",
    "test = transform_df(test)\n",
    "\n",
    "col = [c for c in x1.columns if c not in ['id','target']]\n",
    "x1 = x1[col]\n",
    "x2 = x2[col]\n",
    "\n",
    "watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "model = xgb.train(params, xgb.DMatrix(x1, y1), 5000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "print(gini_xgb(model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), y2))\n",
    "test['target'] = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit)\n",
    "test[['id','target']].to_csv(base_path + 'test_uberKinetics.csv', index=False, float_format='%.5f')\n",
    "\n",
    "train = transform_df(train)\n",
    "train['target'] = model.predict(xgb.DMatrix(train[col]), ntree_limit=model.best_ntree_limit)\n",
    "train[['id','target']].to_csv(base_path + 'train_uberKinetics.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
